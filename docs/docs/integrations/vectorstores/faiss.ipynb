{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "683953b3",
      "metadata": {
        "id": "683953b3"
      },
      "source": [
        "# Faiss\n",
        "\n",
        ">[Facebook AI Similarity Search (FAISS)](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also includes supporting code for evaluation and parameter tuning.\n",
        ">\n",
        ">See [The FAISS Library](https://arxiv.org/pdf/2401.08281) paper.\n",
        "\n",
        "You can find the FAISS documentation at [this page](https://faiss.ai/).\n",
        "\n",
        "This notebook shows how to use functionality related to the `FAISS` vector database. It will show functionality specific to this integration. After going through, it may be useful to explore [relevant use-case pages](/docs/how_to#qa-with-rag) to learn how to use this vectorstore as part of a larger chain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "601ac1d5-48a2-4e41-bf51-f1d5fdd5639d",
      "metadata": {
        "tags": [],
        "id": "601ac1d5-48a2-4e41-bf51-f1d5fdd5639d"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The integration lives in the `langchain-community` package. We also need to install the `faiss` package itself. We can install these with:\n",
        "\n",
        "Note that you can also install `faiss-gpu` if you want to use the GPU enabled version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "08165d56",
      "metadata": {
        "id": "08165d56"
      },
      "outputs": [],
      "source": [
        "pip install -qU langchain-community faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"requests==2.32.4\"\n",
        "!pip install -U langchain langchain-community langchain-openai faiss-cpu"
      ],
      "metadata": {
        "id": "bxnCw45YoECg",
        "outputId": "647b2190-ba68-470f-8035-f4f6c05bfb57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bxnCw45YoECg",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests==2.32.4\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2025.8.3)\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m532.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.3.29 requires requests<3,>=2.32.5, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed requests-2.32.4\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.16)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.101.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Downloading langchain_openai-0.3.32-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m532.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Installing collected packages: requests, langchain-openai\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-openai-0.3.32 requests-2.32.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "408be78f-7b0e-44d4-8d48-56a6cb9b3fb9",
      "metadata": {
        "id": "408be78f-7b0e-44d4-8d48-56a6cb9b3fb9"
      },
      "source": [
        "If you want to get best in-class automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "951c82cb-40bf-46ac-9f3f-d2fca7d204b8",
      "metadata": {
        "id": "951c82cb-40bf-46ac-9f3f-d2fca7d204b8"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78dde98a-584f-4f2a-98d5-e776fd9558fa",
      "metadata": {
        "id": "78dde98a-584f-4f2a-98d5-e776fd9558fa"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "import EmbeddingTabs from \"@theme/EmbeddingTabs\";\n",
        "\n",
        "<EmbeddingTabs/>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# OpenAI APIキーを入力（非表示で入力できる）\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ],
      "metadata": {
        "id": "8HbOVCFfpqdQ",
        "outputId": "db8d7bd0-71c7-49fe-9e80-a70f637c715c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8HbOVCFfpqdQ",
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5b394da3",
      "metadata": {
        "id": "5b394da3"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dc37144c-208d-4ab3-9f3a-0407a69fe052",
      "metadata": {
        "tags": [],
        "id": "dc37144c-208d-4ab3-9f3a-0407a69fe052"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8761614",
      "metadata": {
        "id": "d8761614"
      },
      "source": [
        "## Manage vector store\n",
        "\n",
        "### Add items to vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3867e154",
      "metadata": {
        "id": "3867e154",
        "outputId": "14d66814-c046-4e6e-a15c-7ec9646c2418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cb295199-f10c-4fa3-8088-094de9c95b88',\n",
              " '85b0e6c9-d4be-4622-a250-a83fb5075821',\n",
              " '542bee27-19af-4d59-bb28-66ce5aeb8fcd',\n",
              " 'd62b0ad3-b676-4393-a542-214edb77f887',\n",
              " '2446689c-34d7-465a-8246-2fc33c997668',\n",
              " '40ae43ea-ad4b-4f19-b6be-d966390d24e1',\n",
              " 'c51b1134-0705-4bfb-96a3-a2dd33511fec',\n",
              " '1731cb27-567c-4898-99ad-a7a6d7f38c6b',\n",
              " '0c567ff8-8927-4262-899f-56e902b3c91f',\n",
              " '9fd6b1b7-35f9-427f-a754-f8a4de43ca11']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a410a2dc",
      "metadata": {
        "id": "a410a2dc"
      },
      "source": [
        "### Delete items from vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c3db04bd",
      "metadata": {
        "id": "c3db04bd",
        "outputId": "fd40d821-af43-4732-be02-4efb2e18b8e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "vector_store.delete(ids=[uuids[-1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77de24ff",
      "metadata": {
        "id": "77de24ff"
      },
      "source": [
        "## Query vector store\n",
        "\n",
        "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.\n",
        "\n",
        "### Query directly\n",
        "\n",
        "#### Similarity search\n",
        "\n",
        "Performing a simple similarity search with filtering on metadata can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "53d95d3f",
      "metadata": {
        "id": "53d95d3f",
        "outputId": "492ac177-9e09-47b5-8f93-a41c28c5c771",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39cb1496",
      "metadata": {
        "id": "39cb1496"
      },
      "source": [
        "Some [MongoDB query and projection operators](https://www.mongodb.com/docs/manual/reference/operator/query/) are supported for more advanced metadata filtering. The current list of supported operators are as follows:\n",
        "- `$eq` (equals)\n",
        "- `$neq` (not equals)\n",
        "- `$gt` (greater than)\n",
        "- `$lt` (less than)\n",
        "- `$gte` (greater than or equal)\n",
        "- `$lte` (less than or equal)\n",
        "- `$in` (membership in list)\n",
        "- `$nin` (not in list)\n",
        "- `$and` (all conditions must match)\n",
        "- `$or` (any condition must match)\n",
        "- `$not` (negation of condition)\n",
        "\n",
        "Performing the same above similarity search with advanced metadata filtering can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1b3dd99d",
      "metadata": {
        "id": "1b3dd99d",
        "outputId": "03cd16b7-c792-441f-e55d-b7481dcaeb21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": {\"$eq\": \"tweet\"}},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae35069",
      "metadata": {
        "id": "5ae35069"
      },
      "source": [
        "#### Similarity search with score\n",
        "\n",
        "You can also search with score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a9078ce9",
      "metadata": {
        "id": "a9078ce9",
        "outputId": "9f95d395-d021-4a05-fe91-0410f3acfe50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.893776] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9091b1f",
      "metadata": {
        "id": "e9091b1f"
      },
      "source": [
        "#### Other search methods\n",
        "\n",
        "\n",
        "There are a variety of other ways to search a FAISS vector store. For a complete list of those methods, please refer to the [API Reference](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html)\n",
        "\n",
        "### Query by turning into retriever\n",
        "\n",
        "You can also transform the vector store into a retriever for easier usage in your chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "10da64fa",
      "metadata": {
        "id": "10da64fa",
        "outputId": "65d6dec2-922e-455c-c06d-015dd7a389a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='d62b0ad3-b676-4393-a542-214edb77f887', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1})\n",
        "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5edd1909",
      "metadata": {
        "id": "5edd1909"
      },
      "source": [
        "## Usage for retrieval-augmented generation\n",
        "\n",
        "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
        "\n",
        "- [Tutorials](/docs/tutorials/rag)\n",
        "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
        "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31bda7fd",
      "metadata": {
        "id": "31bda7fd"
      },
      "source": [
        "## Saving and loading\n",
        "You can also save and load a FAISS index. This is useful so you don't have to recreate it everytime you use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1b31fe27-e0b3-42c6-b17c-8270b517ee1f",
      "metadata": {
        "id": "1b31fe27-e0b3-42c6-b17c-8270b517ee1f"
      },
      "outputs": [],
      "source": [
        "vector_store.save_local(\"faiss_index\")\n",
        "\n",
        "new_vector_store = FAISS.load_local(\n",
        "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
        ")\n",
        "\n",
        "docs = new_vector_store.similarity_search(\"qux\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "98378c4e",
      "metadata": {
        "id": "98378c4e",
        "outputId": "d5531437-6d24-40cb-cc90-103bcd917993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id='542bee27-19af-4d59-bb28-66ce5aeb8fcd', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57da60d4",
      "metadata": {
        "id": "57da60d4"
      },
      "source": [
        "## Merging\n",
        "You can also merge two FAISS vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9b8f5e31-3f40-4e94-8d97-5883125efba7",
      "metadata": {
        "id": "9b8f5e31-3f40-4e94-8d97-5883125efba7",
        "outputId": "aee18f9d-b102-4a61-edfa-35c064145bf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'56f83227-28ce-415c-9fe1-6cd26d020327': Document(id='56f83227-28ce-415c-9fe1-6cd26d020327', metadata={}, page_content='foo')}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "db1 = FAISS.from_texts([\"foo\"], embeddings)\n",
        "db2 = FAISS.from_texts([\"bar\"], embeddings)\n",
        "\n",
        "db1.docstore._dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "83392605",
      "metadata": {
        "id": "83392605",
        "outputId": "970d3907-4ac3-46f0-a484-21d79f419f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'730e66aa-88c1-4322-8d24-824f420caca4': Document(id='730e66aa-88c1-4322-8d24-824f420caca4', metadata={}, page_content='bar')}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "db2.docstore._dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a3fcc1c7",
      "metadata": {
        "id": "a3fcc1c7"
      },
      "outputs": [],
      "source": [
        "db1.merge_from(db2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "41c51f89",
      "metadata": {
        "id": "41c51f89",
        "outputId": "33403e45-7553-4979-cd3b-7e5629870e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'56f83227-28ce-415c-9fe1-6cd26d020327': Document(id='56f83227-28ce-415c-9fe1-6cd26d020327', metadata={}, page_content='foo'),\n",
              " '730e66aa-88c1-4322-8d24-824f420caca4': Document(id='730e66aa-88c1-4322-8d24-824f420caca4', metadata={}, page_content='bar')}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "db1.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65654d80",
      "metadata": {
        "id": "65654d80"
      },
      "source": [
        "## API reference\n",
        "\n",
        "For detailed documentation of all `FAISS` vector store features and configurations head to the API reference: https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}